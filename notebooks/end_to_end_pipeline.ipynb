{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Rating Drop Early-Warning System\n",
    "This notebook orchestrates the full analytical pipeline.\n",
    "\n",
    "**Stages:**\n",
    "1. Data Preparation\n",
    "2. Optimized Model Training\n",
    "3. LLM Root Cause Analysis\n",
    "4. Dashboard Generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "YELP RATING DROP EARLY-WARNING SYSTEM\n",
      "Full Pipeline Execution\n",
      "======================================================================\n",
      "\n",
      "Started: 2025-12-01 20:27:37\n",
      "Working directory: /Users/valeira/Desktop/yelp-rating-alert-system\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"YELP RATING DROP EARLY-WARNING SYSTEM\")\n",
    "print(\"Full Pipeline Execution\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nStarted: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Working directory: {os.getcwd()}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Data Preparation\n",
    "\n",
    "Loads raw Yelp data, filters Philadelphia restaurants, cleans and processes.\n",
    "\n",
    "**Outputs:**\n",
    "- `data/processed/reviews_clean.csv`\n",
    "- `data/processed/reviews_features.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STAGE 1: DATA PREPARATION\n",
      "======================================================================\n",
      "Started: 20:27:37\n",
      "\n",
      "Directories created successfully!\n",
      "Total businesses loaded: 150,346\n",
      "Philadelphia restaurants: 5,852\n",
      "\n",
      "Sample business IDs saved for filtering reviews\n",
      "Unique business IDs: 5,852\n",
      "Loading reviews (this may take a few minutes)...\n",
      "Processed 100,000 reviews, found 12,498 Philadelphia reviews\n",
      "Processed 200,000 reviews, found 25,327 Philadelphia reviews\n",
      "Processed 300,000 reviews, found 37,858 Philadelphia reviews\n",
      "Processed 400,000 reviews, found 47,970 Philadelphia reviews\n",
      "Processed 500,000 reviews, found 55,951 Philadelphia reviews\n",
      "Processed 600,000 reviews, found 63,135 Philadelphia reviews\n",
      "Processed 700,000 reviews, found 70,113 Philadelphia reviews\n",
      "Processed 800,000 reviews, found 82,501 Philadelphia reviews\n",
      "Processed 900,000 reviews, found 95,975 Philadelphia reviews\n",
      "Processed 1,000,000 reviews, found 109,595 Philadelphia reviews\n",
      "Processed 1,100,000 reviews, found 121,428 Philadelphia reviews\n",
      "Processed 1,200,000 reviews, found 130,773 Philadelphia reviews\n",
      "Processed 1,300,000 reviews, found 138,966 Philadelphia reviews\n",
      "Processed 1,400,000 reviews, found 146,961 Philadelphia reviews\n",
      "Processed 1,500,000 reviews, found 158,447 Philadelphia reviews\n",
      "Processed 1,600,000 reviews, found 170,722 Philadelphia reviews\n",
      "Processed 1,700,000 reviews, found 183,503 Philadelphia reviews\n",
      "Processed 1,800,000 reviews, found 195,026 Philadelphia reviews\n",
      "Processed 1,900,000 reviews, found 203,375 Philadelphia reviews\n",
      "Processed 2,000,000 reviews, found 209,967 Philadelphia reviews\n",
      "Processed 2,100,000 reviews, found 216,617 Philadelphia reviews\n",
      "Processed 2,200,000 reviews, found 228,285 Philadelphia reviews\n",
      "Processed 2,300,000 reviews, found 241,054 Philadelphia reviews\n",
      "Processed 2,400,000 reviews, found 254,049 Philadelphia reviews\n",
      "Processed 2,500,000 reviews, found 264,766 Philadelphia reviews\n",
      "Processed 2,600,000 reviews, found 273,354 Philadelphia reviews\n",
      "Processed 2,700,000 reviews, found 281,130 Philadelphia reviews\n",
      "Processed 2,800,000 reviews, found 288,358 Philadelphia reviews\n",
      "Processed 2,900,000 reviews, found 299,628 Philadelphia reviews\n",
      "Processed 3,000,000 reviews, found 311,834 Philadelphia reviews\n",
      "Processed 3,100,000 reviews, found 324,373 Philadelphia reviews\n",
      "Processed 3,200,000 reviews, found 334,933 Philadelphia reviews\n",
      "Processed 3,300,000 reviews, found 342,550 Philadelphia reviews\n",
      "Processed 3,400,000 reviews, found 348,740 Philadelphia reviews\n",
      "Processed 3,500,000 reviews, found 355,975 Philadelphia reviews\n",
      "Processed 3,600,000 reviews, found 366,782 Philadelphia reviews\n",
      "Processed 3,700,000 reviews, found 377,723 Philadelphia reviews\n",
      "Processed 3,800,000 reviews, found 388,815 Philadelphia reviews\n",
      "Processed 3,900,000 reviews, found 397,475 Philadelphia reviews\n",
      "Processed 4,000,000 reviews, found 403,927 Philadelphia reviews\n",
      "Processed 4,100,000 reviews, found 409,661 Philadelphia reviews\n",
      "Processed 4,200,000 reviews, found 417,114 Philadelphia reviews\n",
      "Processed 4,300,000 reviews, found 429,198 Philadelphia reviews\n",
      "Processed 4,400,000 reviews, found 441,356 Philadelphia reviews\n",
      "Processed 4,500,000 reviews, found 453,877 Philadelphia reviews\n",
      "Processed 4,600,000 reviews, found 463,114 Philadelphia reviews\n",
      "Processed 4,700,000 reviews, found 471,487 Philadelphia reviews\n",
      "Processed 4,800,000 reviews, found 477,869 Philadelphia reviews\n",
      "Processed 4,900,000 reviews, found 486,241 Philadelphia reviews\n",
      "Processed 5,000,000 reviews, found 498,959 Philadelphia reviews\n",
      "Processed 5,100,000 reviews, found 511,709 Philadelphia reviews\n",
      "Processed 5,200,000 reviews, found 524,287 Philadelphia reviews\n",
      "Processed 5,300,000 reviews, found 534,040 Philadelphia reviews\n",
      "Processed 5,400,000 reviews, found 542,684 Philadelphia reviews\n",
      "Processed 5,500,000 reviews, found 549,256 Philadelphia reviews\n",
      "Processed 5,600,000 reviews, found 556,818 Philadelphia reviews\n",
      "Processed 5,700,000 reviews, found 567,385 Philadelphia reviews\n",
      "Processed 5,800,000 reviews, found 578,064 Philadelphia reviews\n",
      "Processed 5,900,000 reviews, found 588,751 Philadelphia reviews\n",
      "Processed 6,000,000 reviews, found 597,094 Philadelphia reviews\n",
      "Processed 6,100,000 reviews, found 605,136 Philadelphia reviews\n",
      "Processed 6,200,000 reviews, found 610,627 Philadelphia reviews\n",
      "Processed 6,300,000 reviews, found 617,197 Philadelphia reviews\n",
      "Processed 6,400,000 reviews, found 629,891 Philadelphia reviews\n",
      "Processed 6,500,000 reviews, found 642,952 Philadelphia reviews\n",
      "Processed 6,600,000 reviews, found 655,586 Philadelphia reviews\n",
      "Processed 6,700,000 reviews, found 665,808 Philadelphia reviews\n",
      "Processed 6,800,000 reviews, found 673,911 Philadelphia reviews\n",
      "Processed 6,900,000 reviews, found 680,883 Philadelphia reviews\n",
      "\n",
      "Total Philadelphia restaurant reviews: 687,289\n",
      "Review DataFrame shape: (687289, 9)\n",
      "Sampling 100,000 reviews from 687,289 total reviews\n",
      "Merged DataFrame shape: (100000, 13)\n",
      "Columns: ['review_id', 'user_id', 'business_id', 'stars_review', 'useful', 'funny', 'cool', 'text', 'date', 'name', 'city', 'state', 'stars_business']\n",
      "After removing duplicates: 100,000 reviews\n",
      "After removing missing text: 100,000 reviews\n",
      "After removing short reviews: 99,997 reviews\n",
      "\n",
      "Data cleaning complete!\n",
      "============================================================\n",
      "DATASET SUMMARY\n",
      "============================================================\n",
      "Total reviews: 99,997\n",
      "Unique businesses: 5,393\n",
      "Date range: 2005-06-24 to 2022-01-19\n",
      "\n",
      "Rating distribution:\n",
      "stars_review\n",
      "1.0     9922\n",
      "2.0     8317\n",
      "3.0    13261\n",
      "4.0    28348\n",
      "5.0    40149\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Average rating: 3.80\n",
      "Negative reviews (≤2 stars): 18,239 (18.2%)\n",
      "Saved cleaned data to: data/processed/reviews_clean.csv\n",
      "  Shape: (99997, 14)\n",
      "  Size: 70.9 MB\n",
      "\n",
      "✓ Stage 1 completed: 20:27:53\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STAGE 1: DATA PREPARATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Started: {datetime.now().strftime('%H:%M:%S')}\\n\")\n",
    "\n",
    "try:\n",
    "    %run data_prep.ipynb\n",
    "    print(f\"\\n✓ Stage 1 completed: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    stage_1_success = True\n",
    "except Exception as e:\n",
    "    print(f\"\\n✗ Stage 1 failed: {e}\")\n",
    "    stage_1_success = False\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Optimized Model Training\n",
    "\n",
    "Trains Random Forest with:\n",
    "- 31 engineered features\n",
    "- SMOTE for class balance\n",
    "- Optimized decision threshold\n",
    "\n",
    "**Outputs:**\n",
    "- `models/rating_drop_model_optimized.pkl`\n",
    "- `models/model_summary_optimized.csv`\n",
    "- `figures/model_results_optimized.png`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STAGE 2: OPTIMIZED MODEL TRAINING\n",
      "======================================================================\n",
      "Started: 20:27:53\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valeira/miniconda3/envs/dl/lib/python3.11/site-packages/nbformat/__init__.py:96: MissingIDFieldWarning: Cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.\n",
      "  validate(nb)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n",
      "Loaded data from: data/processed/reviews_features.csv\n",
      "Shape: (99997, 27)\n",
      "              business_id                date\n",
      "0  -0M0b-XhtFagyLmsBtOe8w 2012-02-21 18:24:45\n",
      "1  -0M0b-XhtFagyLmsBtOe8w 2013-12-03 23:56:37\n",
      "2  -0M0b-XhtFagyLmsBtOe8w 2015-06-24 22:10:39\n",
      "3  -0PN_KFPtbnLQZEeb23XiA 2011-11-23 22:10:01\n",
      "4  -0TffRSXXIlBYVbb5AwfTg 2013-06-01 01:47:50\n",
      "\n",
      "======================================================================\n",
      "UPGRADING LABEL — FUTURE 7-DAY RATING DROP\n",
      "======================================================================\n",
      "Label distribution (proportion):\n",
      "label_rating_drop\n",
      "0    0.802824\n",
      "1    0.197176\n",
      "Name: proportion, dtype: float64\n",
      "Dropped 10119 rows due to NaNs in key fields.\n",
      "\n",
      "======================================================================\n",
      "PRIORITY 3: ENHANCED FEATURE ENGINEERING\n",
      "======================================================================\n",
      "\n",
      "Creating interaction features...\n",
      "✓ Interaction features created\n",
      "\n",
      "Creating time-based features...\n",
      "✓ Time-based features created\n",
      "\n",
      "Creating business-specific features...\n",
      "✓ Business-specific features created\n",
      "\n",
      "Creating acceleration features...\n",
      "✓ Acceleration features created\n",
      "\n",
      "Enhanced feature engineering complete.\n",
      "Total numeric features used: 31\n",
      "['stars_review', 'useful', 'funny', 'cool', 'stars_business', 'text_length', 'sentiment', 'sentiment_7d', 'sentiment_14d', 'rating_7d', 'rating_14d', 'review_count_7d', 'review_count_14d', 'sentiment_momentum', 'rating_momentum', 'sentiment_slope', 'rating_volatility', 'future_rating_14d', 'rating_drop', 'rating_sentiment_interaction', 'momentum_volatility', 'day_of_week', 'month', 'is_weekend', 'is_holiday_season', 'review_density', 'negative_ratio_7d', 'rating_range_7d', 'sentiment_range_7d', 'sentiment_acceleration', 'rating_acceleration']\n",
      "Removed 40495 rows due to NaNs in features/label.\n",
      "Train shape: (39506, 31)\n",
      "Test shape : (9877, 31)\n",
      "\n",
      "Class distribution before SMOTE:\n",
      "Counter({0: 28757, 1: 10749})\n",
      "Current minority/majority ratio: 0.374\n",
      "Current ratio (0.374) >= desired ratio (0.3), skipping SMOTE.\n",
      "\n",
      "After SMOTE (or skip):\n",
      "X_train_balanced: (39506, 31)\n",
      "y_train_balanced distribution (proportion):\n",
      "label_rating_drop\n",
      "0    0.727915\n",
      "1    0.272085\n",
      "Name: proportion, dtype: float64\n",
      "Random Forest trained with optimized settings.\n",
      "\n",
      "Time-series baseline (Logistic Regression)\n",
      "  AUC:       0.692\n",
      "  Accuracy:  0.629\n",
      "  Precision: 0.392\n",
      "  Recall:    0.661\n",
      "  F1-score:  0.492\n",
      "Best threshold by F1-score: 0.290\n",
      "Best F1-score: 0.575\n",
      "\n",
      "Random Forest (Optimized, best threshold)\n",
      "  AUC:       0.781\n",
      "  Accuracy:  0.718\n",
      "  Precision: 0.487\n",
      "  Recall:    0.701\n",
      "  F1-score:  0.575\n",
      "✓ Saved: figures/threshold_optimization.png\n",
      "\n",
      "MODEL COMPARISON SUMMARY:\n",
      "                    model   auc  accuracy  precision  recall    f1\n",
      "        Gradient Boosting 0.794     0.773      0.644   0.367 0.468\n",
      "  Logistic (All features) 0.790     0.708      0.476   0.735 0.577\n",
      "Random Forest (Optimized) 0.781     0.718      0.487   0.701 0.575\n",
      "       Logistic (TS only) 0.692     0.629      0.392   0.661 0.492\n",
      "\n",
      "✓ Saved: models/model_comparison_summary.csv\n",
      "✓ Saved: figures/model_results_optimized.png\n",
      "\n",
      "Computing SHAP values (this may take some time)...\n",
      "Saved: figures/shap_summary_optimized_rf.png\n",
      "✓ Saved model to: models/rating_drop_model_optimized.pkl\n",
      "✓ Saved feature list to: models/feature_list_optimized.txt\n",
      "✓ Saved: models/model_summary_optimized.csv\n",
      "✓ Saved optimized features to: data/processed/reviews_features_optimized.csv\n",
      "\n",
      "======================================================================\n",
      "MODEL OPTIMIZATION COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Final Model Performance (Random Forest, Optimized):\n",
      "  ROC AUC:   0.781\n",
      "  Accuracy:  0.718\n",
      "  Precision: 0.487\n",
      "  Recall:    0.701\n",
      "  F1-Score:  0.575\n",
      "  Best threshold: 0.290\n",
      "\n",
      "Artifacts saved:\n",
      "  - models/rating_drop_model_optimized.pkl\n",
      "  - models/model_summary_optimized.csv\n",
      "  - models/feature_list_optimized.txt\n",
      "  - models/model_comparison_summary.csv\n",
      "  - figures/model_results_optimized.png\n",
      "  - figures/threshold_optimization.png\n",
      "  - figures/shap_summary_optimized_rf.png\n",
      "  - figures/shap_single_example_optimized_rf.png\n",
      "  - data/processed/reviews_features_optimized.csv\n",
      "\n",
      "✓ Stage 2 completed: 20:28:20\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STAGE 2: OPTIMIZED MODEL TRAINING\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Started: {datetime.now().strftime('%H:%M:%S')}\\n\")\n",
    "\n",
    "try:\n",
    "    %run end_to_end_pipeline.ipynb\n",
    "    print(f\"\\n✓ Stage 2 completed: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    stage_2_success = True\n",
    "except Exception as e:\n",
    "    print(f\"\\n✗ Stage 2 failed: {e}\")\n",
    "    stage_2_success = False\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: LLM Root Cause Analysis\n",
    "\n",
    "Analyzes negative reviews with Llama 3.2 via Ollama.\n",
    "\n",
    "**Prerequisites:** Ollama must be running\n",
    "```bash\n",
    "ollama run llama3.2\n",
    "```\n",
    "\n",
    "**Outputs:**\n",
    "- `results/llm_complaint_analysis.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STAGE 3: LLM ROOT CAUSE ANALYSIS\n",
      "======================================================================\n",
      "Started: 20:28:20\n",
      "\n",
      "✓ Ollama is running\n",
      "\n",
      "Libraries loaded!\n",
      "\n",
      "Make sure Ollama is running with Llama 3.2:\n",
      "  Terminal command: ollama run llama3.2\n",
      "Testing Ollama connection...\n",
      "\n",
      "✓ Ollama is working!\n",
      "\n",
      "Test result:\n",
      "{\n",
      "  \"food_quality\": true,\n",
      "  \"service_speed\": true,\n",
      "  \"staff_behavior\": true,\n",
      "  \"cleanliness\": false,\n",
      "  \"portion_size\": false,\n",
      "  \"pricing\": false,\n",
      "  \"order_accuracy\": false,\n",
      "  \"severity\": \"high\",\n",
      "  \"primary_issue\": \"The food was cold and the waiter was very rude. We waited 45 minutes for our order.\"\n",
      "}\n",
      "Loaded data: 89,878 reviews\n",
      "\n",
      "Negative reviews (≤3 stars): 27,933\n",
      "Selected 20 negative reviews for LLM analysis\n",
      "\n",
      "Rating distribution in sample:\n",
      "stars_review\n",
      "1.0    10\n",
      "2.0     1\n",
      "3.0     9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Analyzing reviews with Llama 3.2...\n",
      "This may take 1-2 minutes (about 1 second per review)\n",
      "\n",
      "Analyzing review 19/20...\n",
      "\n",
      "✓ Analysis complete!\n",
      "  Successful: 19/20\n",
      "  Errors: 1\n",
      "\n",
      "Analyzed 19 reviews\n",
      "\n",
      "DataFrame columns: ['food_quality', 'service_speed', 'staff_behavior', 'cleanliness', 'portion_size', 'pricing', 'order_accuracy', 'severity', 'primary_issue', 'business_id', 'business_name', 'rating', 'date', 'review_text']\n",
      "============================================================\n",
      "COMPLAINT CATEGORY DISTRIBUTION\n",
      "============================================================\n",
      "food_quality        : 12 reviews ( 63.2%)\n",
      "staff_behavior      :  7 reviews ( 36.8%)\n",
      "portion_size        :  6 reviews ( 31.6%)\n",
      "pricing             :  5 reviews ( 26.3%)\n",
      "order_accuracy      :  2 reviews ( 10.5%)\n",
      "service_speed       :  1 reviews (  5.3%)\n",
      "cleanliness         :  1 reviews (  5.3%)\n",
      "\n",
      "============================================================\n",
      "SEVERITY DISTRIBUTION\n",
      "============================================================\n",
      "low                 :  9 reviews ( 47.4%)\n",
      "high                :  8 reviews ( 42.1%)\n",
      "medium              :  2 reviews ( 10.5%)\n",
      "\n",
      "============================================================\n",
      "TOP 5 PRIMARY ISSUES\n",
      "============================================================\n",
      "  • the bouncer did not ask for ID (1 reviews)\n",
      "  • They skimp out on the grilled salmon (1 reviews)\n",
      "  • Rude staff (1 reviews)\n",
      "  • Terrible food, The meat was not even lamb... (1 reviews)\n",
      "  • not very gluten free-friendly (1 reviews)\n",
      "\n",
      "============================================================\n",
      "RESULTS SAVED\n",
      "============================================================\n",
      "✓ File: results/llm_complaint_analysis.csv\n",
      "✓ Reviews analyzed: 19\n",
      "✓ Columns: 14\n",
      "\n",
      "Sample output:\n",
      "            business_name  rating severity                                                                                                                             primary_issue\n",
      "McGillin's Olde Ale House     3.0      low                                                                                                            the bouncer did not ask for ID\n",
      "           El Camino Real     1.0     high The waiter was inattentive and it took over an hour for the food to arrive, with a long delay between initial acknowledgement and arrival\n",
      "                      Pod     3.0      low                                            Dining off the main menu is too expensive and doesn't offer enough of a portion in my opinion.\n",
      "\n",
      "============================================================\n",
      "SUMMARY FOR FINAL REPORT\n",
      "============================================================\n",
      "\n",
      "LLM Implementation:\n",
      "  - Model: Llama 3.2-3B (open-source)\n",
      "  - Deployment: Local inference via Ollama\n",
      "  - Sample analyzed: 19 reviews\n",
      "  - Success rate: 95.0%\n",
      "  - Average processing time: ~1 second per review\n",
      "  - Cost: $0 (local deployment)\n",
      "\n",
      "Top Complaint Categories:\n",
      "  1. food_quality: 63% (12 reviews)\n",
      "  2. staff_behavior: 37% (7 reviews)\n",
      "  3. portion_size: 32% (6 reviews)\n",
      "\n",
      "Key Achievement:\n",
      " Zero-cost LLM deployment for detailed complaint categorization\n",
      " Enables targeted operational improvements\n",
      " Automated root cause identification\n",
      "\n",
      "✓ Stage 3 completed: 20:28:58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/ln88kc6d3qn6v_mv1kg4krsc0000gn/T/ipykernel_23179/549459008.py:13: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  category_flags = complaint_df[available_cols].applymap(\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STAGE 3: LLM ROOT CAUSE ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Started: {datetime.now().strftime('%H:%M:%S')}\\n\")\n",
    "\n",
    "# Check Ollama availability\n",
    "try:\n",
    "    import requests\n",
    "\n",
    "    response = requests.get(\"http://localhost:11434/api/tags\", timeout=2)\n",
    "    if response.status_code == 200:\n",
    "        print(\"✓ Ollama is running\\n\")\n",
    "        ollama_available = True\n",
    "    else:\n",
    "        print(\"⚠ Ollama not responding properly\\n\")\n",
    "        ollama_available = False\n",
    "except:\n",
    "    print(\"⚠ Cannot connect to Ollama\")\n",
    "    print(\"  Start it with: ollama run llama3.2\\n\")\n",
    "    ollama_available = False\n",
    "\n",
    "if ollama_available:\n",
    "    try:\n",
    "        %run llm_root_cause_analysis.ipynb\n",
    "        print(f\"\\n✓ Stage 3 completed: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "        stage_3_success = True\n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ Stage 3 failed: {e}\")\n",
    "        print(\"Continuing to dashboards...\")\n",
    "        stage_3_success = False\n",
    "else:\n",
    "    print(\"Skipping LLM analysis (Ollama not available)\")\n",
    "    stage_3_success = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4: Dashboard Generation & Final Report\n",
    "\n",
    "Creates interactive dashboards and comprehensive report.\n",
    "\n",
    "**Outputs:**\n",
    "- `dashboards/dashboard_overview.html`\n",
    "- `dashboards/dashboard_alerts.html`\n",
    "- `dashboards/trend_analysis.html`\n",
    "- `reports/final_project_report.txt`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STAGE 4: DASHBOARDS & FINAL REPORT\n",
      "======================================================================\n",
      "Started: 20:28:58\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valeira/miniconda3/envs/dl/lib/python3.11/site-packages/nbformat/__init__.py:96: MissingIDFieldWarning: Cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.\n",
      "  validate(nb)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported and output directories ensured.\n",
      "Loaded optimized features from: data/processed/reviews_features_optimized.csv\n",
      "Shape: (89878, 41)\n",
      "Loaded optimized model from: models/rating_drop_model_optimized.pkl\n",
      "Loaded 31 features from: models/feature_list_optimized.txt\n",
      "Using 31 features present in dataset.\n",
      "Loaded model summary from: models/model_summary_optimized.csv\n",
      "Loaded LLM complaint analysis from: results/llm_complaint_analysis.csv\n",
      "Computed risk scores and risk_flag using optimal threshold: 0.29\n",
      "              business_id                                   name  \\\n",
      "0  -0M0b-XhtFagyLmsBtOe8w                         Paris Wine Bar   \n",
      "1  -0TffRSXXIlBYVbb5AwfTg  IndeBlue Modern Indian Food & Spirits   \n",
      "2  -0TffRSXXIlBYVbb5AwfTg  IndeBlue Modern Indian Food & Spirits   \n",
      "3  -0TffRSXXIlBYVbb5AwfTg  IndeBlue Modern Indian Food & Spirits   \n",
      "4  -0TffRSXXIlBYVbb5AwfTg  IndeBlue Modern Indian Food & Spirits   \n",
      "\n",
      "                 date  stars_business  risk_score  risk_flag  \n",
      "0 2015-06-24 22:10:39             3.5    0.426102          1  \n",
      "1 2013-06-27 13:44:37             4.5    0.223922          0  \n",
      "2 2013-08-03 13:56:04             4.5    0.232762          0  \n",
      "3 2013-09-15 17:18:13             4.5    0.187257          0  \n",
      "4 2013-09-18 02:20:26             4.5    0.204912          0  \n",
      "Business-level summary shape: (4094, 7)\n",
      "                 business_id                         name  avg_rating  \\\n",
      "1755  QX6qD3JEopZSH2SQsmObxg                Xi'an Cuisine         3.0   \n",
      "3136  kr6FpW5rMNp_OX8Ha4j0Fw  Amasi Restaurant and Hookah         3.5   \n",
      "2824  gU39t80dXx9LkIZHp6cyCQ                Magic Noodles         3.5   \n",
      "366   4zEqYybRD1FQssLGaJnNZA                 The Blockley         3.5   \n",
      "2455  b1pdnbYvBdtTxJOOom5WmA               Andy's Chicken         4.0   \n",
      "\n",
      "      latest_rating  avg_risk_score  max_risk_score  n_reviews  \n",
      "1755            3.0        0.616899        0.645203          6  \n",
      "3136            3.5        0.602955        0.602955          1  \n",
      "2824            3.5        0.600151        0.640090          4  \n",
      "366             3.5        0.585570        0.585570          1  \n",
      "2455            4.0        0.575911        0.626122          6  \n",
      "✓ Saved overview dashboard to: dashboards/dashboard_overview.html\n",
      "✓ Saved alerts dashboard to: dashboards/dashboard_alerts.html\n",
      "✓ Saved LLM complaint dashboard to: dashboards/dashboard_llm_complaints.html\n",
      "✓ Saved dashboard summary report to: reports/4_dashboard.txt\n",
      "\n",
      "======================================================================\n",
      "DASHBOARDS & REPORT GENERATION COMPLETE (OPTIMIZED PIPELINE)\n",
      "======================================================================\n",
      "\n",
      "Generated files:\n",
      "  - dashboards/dashboard_overview.html\n",
      "  - dashboards/dashboard_alerts.html\n",
      "  - dashboards/dashboard_llm_complaints.html (if LLM results available)\n",
      "  - reports/4_dashboard.txt\n",
      "\n",
      "✓ Stage 4 completed: 20:28:59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/ln88kc6d3qn6v_mv1kg4krsc0000gn/T/ipykernel_23179/4176902861.py:13: FutureWarning:\n",
      "\n",
      "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STAGE 4: DASHBOARDS & FINAL REPORT\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Started: {datetime.now().strftime('%H:%M:%S')}\\n\")\n",
    "\n",
    "try:\n",
    "    %run rating_drop_model.ipynb\n",
    "    print(f\"\\n✓ Stage 4 completed: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    stage_4_success = True\n",
    "except Exception as e:\n",
    "    print(f\"\\n✗ Stage 4 failed: {e}\")\n",
    "    stage_4_success = False\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PIPELINE EXECUTION SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Completed: 2025-12-01 20:28:59\n",
      "\n",
      "Stage Results:\n",
      "  1. Data Preparation:          ✓ SUCCESS\n",
      "  2. Model Training:            ✓ SUCCESS\n",
      "  3. LLM Analysis:              ✓ SUCCESS\n",
      "  4. Dashboards & Report:       ✓ SUCCESS\n",
      "\n",
      "Overall Status: ✓ PIPELINE COMPLETE\n",
      "Note: LLM stage is optional and does not affect overall success.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PIPELINE EXECUTION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nCompleted: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"\\nStage Results:\")\n",
    "print(\n",
    "    f\"  1. Data Preparation:          {'✓ SUCCESS' if stage_1_success else '✗ FAILED'}\"\n",
    ")\n",
    "print(\n",
    "    f\"  2. Model Training:            {'✓ SUCCESS' if stage_2_success else '✗ FAILED'}\"\n",
    ")\n",
    "print(\n",
    "    f\"  3. LLM Analysis:              {'✓ SUCCESS' if stage_3_success else '⚠ SKIPPED/FAILED'}\"\n",
    ")\n",
    "print(\n",
    "    f\"  4. Dashboards & Report:       {'✓ SUCCESS' if stage_4_success else '✗ FAILED'}\"\n",
    ")\n",
    "\n",
    "all_critical_success = stage_1_success and stage_2_success and stage_4_success\n",
    "print(\n",
    "    f\"\\nOverall Status: {'✓ PIPELINE COMPLETE' if all_critical_success else '⚠ PIPELINE INCOMPLETE'}\"\n",
    ")\n",
    "print(f\"Note: LLM stage is optional and does not affect overall success.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Verification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "OUTPUT VERIFICATION\n",
      "======================================================================\n",
      "\n",
      "Data Files:\n",
      "  ✓ data/processed/reviews_clean.csv                        70.9 MB\n",
      "  ✓ data/processed/reviews_features.csv                     84.0 MB\n",
      "  ✓ data/processed/reviews_features_optimized.csv           85.1 MB\n",
      "\n",
      "Model Files:\n",
      "  ✓ models/rating_drop_model_optimized.pkl                   9.9 MB\n",
      "  ✓ models/model_summary_optimized.csv                       0.4 KB\n",
      "  ✓ models/feature_list_optimized.txt                        0.4 KB\n",
      "\n",
      "Figures:\n",
      "  ✓ figures/model_results_optimized.png                     83.8 KB\n",
      "  ✓ figures/threshold_optimization.png                      53.0 KB\n",
      "\n",
      "Dashboards:\n",
      "  ✓ dashboards/dashboard_overview.html                      12.2 MB\n",
      "  ✓ dashboards/dashboard_alerts.html                         4.6 MB\n",
      "\n",
      "Results:\n",
      "  ✓ results/llm_complaint_analysis.csv                       6.7 KB\n",
      "\n",
      "======================================================================\n",
      "✓ Pipeline verification complete\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"OUTPUT VERIFICATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "expected_files = {\n",
    "    \"Data Files\": [\n",
    "        \"data/processed/reviews_clean.csv\",\n",
    "        \"data/processed/reviews_features.csv\",\n",
    "        \"data/processed/reviews_features_optimized.csv\",\n",
    "    ],\n",
    "    \"Model Files\": [\n",
    "        \"models/rating_drop_model_optimized.pkl\",\n",
    "        \"models/model_summary_optimized.csv\",\n",
    "        \"models/feature_list_optimized.txt\",\n",
    "    ],\n",
    "    \"Figures\": [\n",
    "        \"figures/model_results_optimized.png\",\n",
    "        \"figures/threshold_optimization.png\",\n",
    "    ],\n",
    "    \"Dashboards\": [\n",
    "        \"dashboards/dashboard_overview.html\",\n",
    "        \"dashboards/dashboard_alerts.html\",\n",
    "    ],\n",
    "    \"Results\": [\n",
    "        \"results/llm_complaint_analysis.csv\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "for category, files in expected_files.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for filepath in files:\n",
    "        exists = os.path.exists(filepath)\n",
    "        if exists:\n",
    "            size = os.path.getsize(filepath) / 1024\n",
    "            size_str = f\"{size:.1f} KB\" if size < 1024 else f\"{size / 1024:.1f} MB\"\n",
    "        else:\n",
    "            size_str = \"N/A\"\n",
    "        status = \"✓\" if exists else \"✗\"\n",
    "        print(f\"  {status} {filepath:50s} {size_str:>12s}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"✓ Pipeline verification complete\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **View Dashboards:** Open HTML files in `dashboards/` with a browser\n",
    "2. **Read Report:** Check `reports/final_project_report.txt`\n",
    "3. **Review Metrics:** See `models/model_summary_optimized.csv`\n",
    "4. **Analyze Results:** Examine `results/llm_complaint_analysis.csv`\n",
    "\n",
    "---\n",
    "\n",
    "**Project:** Yelp Rating Drop Early-Warning System  \n",
    "**Author:** Fancheng  \n",
    "**Institution:** UC San Diego, MSBA Program\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
