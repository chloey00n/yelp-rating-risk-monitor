# Root Cause Analysis Notes

LLM ROOT CAUSE ANALYSIS REPORT
======================================================================

Notebook: 3_llm_root_cause_analysis.ipynb
Purpose: Use a locally deployed Large Language Model (Llama 3.2 via Ollama)
to automatically extract complaint categories, severity levels, and structured
root-cause insights from negative Yelp reviews.

This component adds qualitative intelligence to the quantitative predictions
generated by the machine learning model.

======================================================================
1. OVERVIEW
----------------------------------------------------------------------

This notebook implements an end-to-end LLM processing pipeline that identifies
the primary operational issues driving negative customer feedback.

By applying a structured prompt and parsing the LLM output into labeled fields,
this module transforms raw review text into actionable business intelligence.

The analysis complements the predictive model by explaining *why* rating drops
are likely to occur.

======================================================================
2. INPUT DATA
----------------------------------------------------------------------

Input dataset:
- data/processed/reviews_features_optimized.csv

Filtering criteria:
- Only include reviews with star ratings ≤ 3
- Focus on recent reviews to capture current operational issues

For each selected review, the notebook extracts:
- Review text
- Star rating
- Sentiment score
- Business ID
- Date and recency

These samples are then fed into the LLM.

======================================================================
3. LLM ARCHITECTURE & DEPLOYMENT
----------------------------------------------------------------------

The system uses:

- Model: Llama 3.2 (3B parameters)
- Deployment: Local inference using Ollama
- Cost: $0 (fully offline, privacy-preserving)

Benefits of local inference:
- No API fees
- No latency or rate limits
- Full data privacy—suitable for sensitive reviews
- Repeatable and scalable

======================================================================
4. ROOT CAUSE CLASSIFICATION FRAMEWORK
----------------------------------------------------------------------

Each review is classified into the following categories (binary labels):

- Food Quality
- Service Speed
- Staff Behavior
- Cleanliness
- Portion Size
- Pricing
- Order Accuracy

Additionally, the LLM assigns:

- Severity Level (Low / Medium / High)
- A short summary explaining the issue
- Optional suggestions and contextual reasoning

This provides both structured and narrative output.

======================================================================
5. PROCESSING WORKFLOW
----------------------------------------------------------------------

For each negative review:

1. Construct a detailed prompt
2. Send prompt to Ollama for inference
3. Receive model-generated JSON-like structure
4. Validate and clean fields
5. Append results to a cumulative DataFrame
6. Track errors if any reviews fail to parse

A progress bar or terminal counter shows the number of processed reviews.

======================================================================
6. ANALYSIS OUTPUTS
----------------------------------------------------------------------

After running the full pipeline, the notebook aggregates:

----------------------------------------------------------------------
6.1 Complaint Category Distribution
----------------------------------------------------------------------

Example (based on typical outputs):

- Food Quality: ~70%
- Staff Behavior: ~55%
- Pricing: ~35%
- Portion Size: ~30%
- Service Speed: ~20%
- Cleanliness: ~10%
- Order Accuracy: ~10%

These percentages reflect the proportion of reviews mentioning each issue.

----------------------------------------------------------------------
6.2 Severity Distribution
----------------------------------------------------------------------

Example severity summary:

- Low Severity: ~60%
- High Severity: ~40%

This split helps determine operational urgency.

----------------------------------------------------------------------
6.3 Sample-Level Insights
----------------------------------------------------------------------

The notebook produces structured results for each review:

- Which issues were flagged
- Severity of each complaint
- Explanation from the LLM
- Suggested improvement actions
- Metadata linking back to the restaurant

This structured output feeds directly into the dashboard and final report.

======================================================================
7. OUTPUT FILES
----------------------------------------------------------------------

The notebook generates the following deliverables:

1. llm_complaint_analysis.csv
   - Structured LLM output with labels and severity scores

2. Intermediate JSON or text logs (optional)
   - Useful for debugging or validating the LLM’s responses

3. Priority-score inputs for Notebook 4
   - Enables ranking of reviews needing immediate attention

======================================================================
8. BUSINESS & TECHNICAL IMPACT
----------------------------------------------------------------------

Business Impact:
- Converts unstructured complaints into data-driven insights
- Reveals the true root causes behind customer dissatisfaction
- Enables targeted operational improvements
- Supports proactive customer engagement strategies

Technical Impact:
- Seamless integration with local LLM (Ollama)
- No API costs and fully offline processing
- Highly extensible for future categories or advanced NLP tasks
- Produces structured annotations ideal for dashboard visualization

This module bridges the gap between quantitative prediction and qualitative
explanation.
