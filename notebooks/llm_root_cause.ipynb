{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: LLM Root Cause Analysis\n",
    "Use Llama 3.2 (via Ollama) to analyze negative reviews and identify complaint categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded!\n",
      "\n",
      "Make sure Ollama is running with Llama 3.2:\n",
      "  Terminal command: ollama run llama3.2\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from time import sleep\n",
    "import os\n",
    "\n",
    "print(\"Libraries loaded!\")\n",
    "print(\"\\nMake sure Ollama is running with Llama 3.2:\")\n",
    "print(\"  Terminal command: ollama run llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_with_ollama(review_text):\n",
    "    \"\"\"\n",
    "    Analyze restaurant review using local Ollama LLM (Llama 3.2)\n",
    "    Returns structured JSON with complaint categories and severity\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"Analyze this restaurant review and identify complaint categories.\n",
    "Return ONLY a valid JSON object with no other text.\n",
    "\n",
    "Review: \"{review_text}\"\n",
    "\n",
    "JSON format (use true/false for categories):\n",
    "{{\n",
    "  \"food_quality\": false,\n",
    "  \"service_speed\": false,\n",
    "  \"staff_behavior\": false,\n",
    "  \"cleanliness\": false,\n",
    "  \"portion_size\": false,\n",
    "  \"pricing\": false,\n",
    "  \"order_accuracy\": false,\n",
    "  \"severity\": \"low|medium|high\",\n",
    "  \"primary_issue\": \"brief description\"\n",
    "}}\n",
    "\n",
    "Set category to true if mentioned in the review. Severity: low=minor, medium=moderate, high=severe.\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            'http://localhost:11434/api/generate',\n",
    "            json={\n",
    "                \"model\": \"llama3.2\",\n",
    "                \"prompt\": prompt,\n",
    "                \"stream\": False\n",
    "            },\n",
    "            timeout=30\n",
    "        )\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            return None\n",
    "        \n",
    "        result_text = response.json()['response']\n",
    "        \n",
    "        # Extract JSON from response\n",
    "        json_start = result_text.find('{')\n",
    "        json_end = result_text.rfind('}') + 1\n",
    "        \n",
    "        if json_start >= 0 and json_end > json_start:\n",
    "            json_str = result_text[json_start:json_end]\n",
    "            return json.loads(json_str)\n",
    "        else:\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Ollama connection...\n",
      "\n",
      "✓ Ollama is working!\n",
      "\n",
      "Test result:\n",
      "{\n",
      "  \"food_quality\": true,\n",
      "  \"service_speed\": true,\n",
      "  \"staff_behavior\": true,\n",
      "  \"cleanliness\": false,\n",
      "  \"portion_size\": false,\n",
      "  \"pricing\": false,\n",
      "  \"order_accuracy\": false,\n",
      "  \"severity\": \"low\",\n",
      "  \"primary_issue\": \"The food was cold and the waiter was very rude. We waited 45 minutes for our order.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Test Ollama connection\n",
    "print(\"Testing Ollama connection...\\n\")\n",
    "\n",
    "test_review = \"The food was cold and the waiter was very rude. We waited 45 minutes for our order.\"\n",
    "test_result = analyze_with_ollama(test_review)\n",
    "\n",
    "if test_result:\n",
    "    print(\"✓ Ollama is working!\")\n",
    "    print(f\"\\nTest result:\")\n",
    "    print(json.dumps(test_result, indent=2))\n",
    "else:\n",
    "    print(\"❌ Ollama connection failed!\")\n",
    "    print(\"\\nPlease check:\")\n",
    "    print(\"  1. Is Ollama running? (Terminal: ollama run llama3.2)\")\n",
    "    print(\"  2. Is port 11434 available?\")\n",
    "    print(\"  3. Is llama3.2 model installed? (ollama pull llama3.2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data: 89,878 reviews\n",
      "\n",
      "Negative reviews (≤3 stars): 27,933\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load feature-engineered data from optimized pipeline\n",
    "\n",
    "df = pd.read_csv(\"data/processed/reviews_features_optimized.csv\")\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "\n",
    "print(f\"Loaded data: {len(df):,} reviews\")\n",
    "print(f\"\\nNegative reviews (≤3 stars): {(df['stars_review'] <= 3).sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 20 negative reviews for LLM analysis\n",
      "\n",
      "Rating distribution in sample:\n",
      "stars_review\n",
      "1.0    10\n",
      "2.0     1\n",
      "3.0     9\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Sample negative reviews for analysis\n",
    "# Note: Using smaller sample due to LLM processing time\n",
    "sample_size = 20\n",
    "\n",
    "negative_reviews = df[df['stars_review'] <= 3].sample(\n",
    "    n=min(sample_size, len(df[df['stars_review'] <= 3])),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Selected {len(negative_reviews)} negative reviews for LLM analysis\")\n",
    "print(f\"\\nRating distribution in sample:\")\n",
    "print(negative_reviews['stars_review'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing reviews with Llama 3.2...\n",
      "This may take 1-2 minutes (about 1 second per review)\n",
      "\n",
      "Analyzing review 20/20...\n",
      "\n",
      "✓ Analysis complete!\n",
      "  Successful: 20/20\n",
      "  Errors: 0\n"
     ]
    }
   ],
   "source": [
    "# Analyze reviews with LLM\n",
    "print(\"\\nAnalyzing reviews with Llama 3.2...\")\n",
    "print(\"This may take 1-2 minutes (about 1 second per review)\\n\")\n",
    "\n",
    "results = []\n",
    "errors = 0\n",
    "\n",
    "for idx, row in negative_reviews.iterrows():\n",
    "    print(f\"Analyzing review {len(results)+1}/{len(negative_reviews)}...\", end='\\r')\n",
    "    \n",
    "    analysis = analyze_with_ollama(row['text'])\n",
    "    \n",
    "    if analysis:\n",
    "        # Add metadata\n",
    "        analysis['business_id'] = row['business_id']\n",
    "        analysis['business_name'] = row.get('name', 'Unknown')\n",
    "        analysis['rating'] = row['stars_review']\n",
    "        analysis['date'] = str(row['date'])\n",
    "        analysis['review_text'] = row['text'][:200] + '...' if len(row['text']) > 200 else row['text']\n",
    "        results.append(analysis)\n",
    "    else:\n",
    "        errors += 1\n",
    "    \n",
    "    # Rate limiting to avoid overloading local LLM\n",
    "    sleep(0.5)\n",
    "\n",
    "print(f\"\\n\\n✓ Analysis complete!\")\n",
    "print(f\"  Successful: {len(results)}/{len(negative_reviews)}\")\n",
    "print(f\"  Errors: {errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzed 20 reviews\n",
      "\n",
      "DataFrame columns: ['food_quality', 'service_speed', 'staff_behavior', 'cleanliness', 'portion_size', 'pricing', 'order_accuracy', 'severity', 'primary_issue', 'business_id', 'business_name', 'rating', 'date', 'review_text']\n"
     ]
    }
   ],
   "source": [
    "# Convert results to DataFrame\n",
    "if len(results) > 0:\n",
    "    complaint_df = pd.DataFrame(results)\n",
    "    \n",
    "    print(f\"\\nAnalyzed {len(complaint_df)} reviews\")\n",
    "    print(f\"\\nDataFrame columns: {complaint_df.columns.tolist()}\")\n",
    "else:\n",
    "    print(\"❌ No results to analyze. Please check Ollama connection.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COMPLAINT CATEGORY DISTRIBUTION\n",
      "============================================================\n",
      "food_quality        : 14 reviews ( 70.0%)\n",
      "staff_behavior      :  7 reviews ( 35.0%)\n",
      "portion_size        :  6 reviews ( 30.0%)\n",
      "pricing             :  6 reviews ( 30.0%)\n",
      "order_accuracy      :  3 reviews ( 15.0%)\n",
      "cleanliness         :  2 reviews ( 10.0%)\n",
      "service_speed       :  1 reviews (  5.0%)\n",
      "\n",
      "============================================================\n",
      "SEVERITY DISTRIBUTION\n",
      "============================================================\n",
      "low                 : 10 reviews ( 50.0%)\n",
      "high                :  9 reviews ( 45.0%)\n",
      "medium              :  1 reviews (  5.0%)\n",
      "\n",
      "============================================================\n",
      "TOP 5 PRIMARY ISSUES\n",
      "============================================================\n",
      "  • skimped on portion size of grilled salmon (1 reviews)\n",
      "  • Rude staff who hung up the phone and claimed they had no reservations when asked about a reservation. (1 reviews)\n",
      "  • Terrible food (1 reviews)\n",
      "  • gluten free options (1 reviews)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/ln88kc6d3qn6v_mv1kg4krsc0000gn/T/ipykernel_9004/839512333.py:14: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  category_flags = complaint_df[available_cols].applymap(\n"
     ]
    }
   ],
   "source": [
    "# Analyze complaint categories\n",
    "if len(results) > 0:\n",
    "    \n",
    "    category_cols = [\n",
    "        'food_quality', 'service_speed', 'staff_behavior',\n",
    "        'cleanliness', 'portion_size', 'pricing', 'order_accuracy'\n",
    "    ]\n",
    "    \n",
    "    # Filter to only existing columns\n",
    "    available_cols = [col for col in category_cols if col in complaint_df.columns]\n",
    "    \n",
    "    if available_cols:\n",
    "        category_flags = complaint_df[available_cols].applymap(\n",
    "            lambda v: 1 if v is True else 0 \n",
    "        )\n",
    "        category_counts = category_flags.sum().sort_values(ascending=False)\n",
    "\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(\"COMPLAINT CATEGORY DISTRIBUTION\")\n",
    "        print(\"=\" * 60)\n",
    "        for category, count in category_counts.items():\n",
    "            percentage = (count / len(complaint_df)) * 100\n",
    "            print(f\"{category:20s}: {int(count):2d} reviews ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # Severity distribution\n",
    "    if 'severity' in complaint_df.columns:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"SEVERITY DISTRIBUTION\")\n",
    "        print(\"=\" * 60)\n",
    "        severity_counts = complaint_df['severity'].value_counts()\n",
    "        for severity, count in severity_counts.items():\n",
    "            percentage = (count / len(complaint_df)) * 100\n",
    "            print(f\"{severity:20s}: {int(count):2d} reviews ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # Top primary issues\n",
    "    if 'primary_issue' in complaint_df.columns:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"TOP 5 PRIMARY ISSUES\")\n",
    "        print(\"=\" * 60)\n",
    "        top_issues = complaint_df['primary_issue'].value_counts().head(5)\n",
    "        for issue, count in top_issues.items():\n",
    "            if issue and str(issue).strip():  # Skip empty issues\n",
    "                print(f\"  • {issue} ({int(count)} reviews)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RESULTS SAVED\n",
      "============================================================\n",
      "✓ File: results/llm_complaint_analysis.csv\n",
      "✓ Reviews analyzed: 20\n",
      "✓ Columns: 14\n",
      "\n",
      "Sample output:\n",
      "            business_name  rating severity                                                                                  primary_issue\n",
      "McGillin's Olde Ale House     3.0      low                                                                                               \n",
      "           El Camino Real     1.0      low Staff were inattentive and failed to check in with customers, leading to a long wait for food.\n",
      "                      Pod     3.0      low Dining off the main menu is too expensive and doesn't offer enough of a portion in my opinion.\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "if len(results) > 0:\n",
    "    output_file = 'results/llm_complaint_analysis.csv'\n",
    "    complaint_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"RESULTS SAVED\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"✓ File: {output_file}\")\n",
    "    print(f\"✓ Reviews analyzed: {len(complaint_df)}\")\n",
    "    print(f\"✓ Columns: {complaint_df.shape[1]}\")\n",
    "    print(f\"\\nSample output:\")\n",
    "    print(complaint_df[['business_name', 'rating', 'severity', 'primary_issue']].head(3).to_string(index=False))\n",
    "else:\n",
    "    print(\"\\n❌ No results to save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUMMARY FOR FINAL REPORT\n",
      "============================================================\n",
      "\n",
      "LLM Implementation:\n",
      "  - Model: Llama 3.2-3B (open-source)\n",
      "  - Deployment: Local inference via Ollama\n",
      "  - Sample analyzed: 20 reviews\n",
      "  - Success rate: 100.0%\n",
      "  - Average processing time: ~1 second per review\n",
      "  - Cost: $0 (local deployment)\n",
      "\n",
      "Top Complaint Categories:\n",
      "  1. food_quality: 70% (14 reviews)\n",
      "  2. staff_behavior: 35% (7 reviews)\n",
      "  3. portion_size: 30% (6 reviews)\n",
      "\n",
      "Key Achievement:\n",
      " Zero-cost LLM deployment for detailed complaint categorization\n",
      " Enables targeted operational improvements\n",
      " Automated root cause identification\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics for report\n",
    "if len(results) > 0:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"SUMMARY FOR FINAL REPORT\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nLLM Implementation:\")\n",
    "    print(f\"  - Model: Llama 3.2-3B (open-source)\")\n",
    "    print(f\"  - Deployment: Local inference via Ollama\")\n",
    "    print(f\"  - Sample analyzed: {len(complaint_df)} reviews\")\n",
    "    print(f\"  - Success rate: {len(complaint_df)/len(negative_reviews)*100:.1f}%\")\n",
    "    print(f\"  - Average processing time: ~1 second per review\")\n",
    "    print(f\"  - Cost: $0 (local deployment)\")\n",
    "    \n",
    "    if available_cols:\n",
    "        print(f\"\\nTop Complaint Categories:\")\n",
    "        for i, (category, count) in enumerate(category_counts.head(3).items(), 1):\n",
    "            percentage = (count / len(complaint_df)) * 100\n",
    "            print(f\"  {i}. {category}: {percentage:.0f}% ({int(count)} reviews)\")\n",
    "    \n",
    "    print(\"\\nKey Achievement:\")\n",
    "    print(\" Zero-cost LLM deployment for detailed complaint categorization\")\n",
    "    print(\" Enables targeted operational improvements\")\n",
    "    print(\" Automated root cause identification\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
